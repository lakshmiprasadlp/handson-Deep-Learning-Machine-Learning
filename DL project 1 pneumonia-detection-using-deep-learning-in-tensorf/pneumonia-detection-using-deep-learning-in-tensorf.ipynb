{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass#print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:11:47.732882Z","iopub.execute_input":"2025-02-06T15:11:47.733160Z","iopub.status.idle":"2025-02-06T15:12:13.465380Z","shell.execute_reply.started":"2025-02-06T15:11:47.733138Z","shell.execute_reply":"2025-02-06T15:12:13.464466Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Flatten\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:12:13.466244Z","iopub.execute_input":"2025-02-06T15:12:13.466593Z","iopub.status.idle":"2025-02-06T15:12:24.891334Z","shell.execute_reply.started":"2025-02-06T15:12:13.466572Z","shell.execute_reply":"2025-02-06T15:12:24.890654Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Dataset Paths\ndataset_path = \"/kaggle/input/chest-xray-pneumonia/chest_xray\"\ntrain_path = dataset_path + \"/train\"\ntest_path = dataset_path + \"/test\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:12:24.895230Z","iopub.execute_input":"2025-02-06T15:12:24.895528Z","iopub.status.idle":"2025-02-06T15:12:24.899210Z","shell.execute_reply.started":"2025-02-06T15:12:24.895504Z","shell.execute_reply":"2025-02-06T15:12:24.898318Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load the VGG16 model\nbase_model = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:12:24.899881Z","iopub.execute_input":"2025-02-06T15:12:24.900201Z","iopub.status.idle":"2025-02-06T15:12:27.777917Z","shell.execute_reply.started":"2025-02-06T15:12:24.900165Z","shell.execute_reply":"2025-02-06T15:12:27.777272Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Freeze all the layers in the base model\nfor layer in base_model.layers:\n    layer.trainable = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:12:27.778860Z","iopub.execute_input":"2025-02-06T15:12:27.779202Z","iopub.status.idle":"2025-02-06T15:12:27.783218Z","shell.execute_reply.started":"2025-02-06T15:12:27.779170Z","shell.execute_reply":"2025-02-06T15:12:27.782568Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"x = Flatten()(base_model.output)\nx = Dense(256, activation='relu')(x)\nx = Dense(2, activation='softmax')(x)  # 2 classes: Normal, Pneumonia\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:12:36.243928Z","iopub.execute_input":"2025-02-06T15:12:36.244283Z","iopub.status.idle":"2025-02-06T15:12:36.268839Z","shell.execute_reply.started":"2025-02-06T15:12:36.244255Z","shell.execute_reply":"2025-02-06T15:12:36.268234Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Define the model\nmodel = Model(inputs=base_model.input, outputs=x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:12:49.813261Z","iopub.execute_input":"2025-02-06T15:12:49.813670Z","iopub.status.idle":"2025-02-06T15:12:49.822072Z","shell.execute_reply.started":"2025-02-06T15:12:49.813622Z","shell.execute_reply":"2025-02-06T15:12:49.820811Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Data Augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load training and test data\ntraining_set = train_datagen.flow_from_directory(train_path, target_size=(224, 224), batch_size=10, class_mode='categorical')\ntest_set = test_datagen.flow_from_directory(test_path, target_size=(224, 224), batch_size=10, class_mode='categorical')\n\n# Train the model\nhistory = model.fit(training_set, validation_data=test_set, epochs=10)\n\n# Save the model\nmodel.save('chest_xray.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:13:02.823960Z","iopub.execute_input":"2025-02-06T15:13:02.824342Z","iopub.status.idle":"2025-02-06T15:30:13.087020Z","shell.execute_reply.started":"2025-02-06T15:13:02.824314Z","shell.execute_reply":"2025-02-06T15:30:13.086092Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Found 5216 images belonging to 2 classes.\nFound 624 images belonging to 2 classes.\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 271ms/step - accuracy: 0.8921 - loss: 0.4660 - val_accuracy: 0.9279 - val_loss: 0.2524\nEpoch 2/10\n\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 193ms/step - accuracy: 0.9447 - loss: 0.1484 - val_accuracy: 0.9054 - val_loss: 0.3218\nEpoch 3/10\n\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 184ms/step - accuracy: 0.9621 - loss: 0.1099 - val_accuracy: 0.9022 - val_loss: 0.3363\nEpoch 4/10\n\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 182ms/step - accuracy: 0.9655 - loss: 0.0912 - val_accuracy: 0.9151 - val_loss: 0.2616\nEpoch 5/10\n\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 183ms/step - accuracy: 0.9679 - loss: 0.0879 - val_accuracy: 0.9183 - val_loss: 0.2577\nEpoch 6/10\n\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 183ms/step - accuracy: 0.9730 - loss: 0.0763 - val_accuracy: 0.8798 - val_loss: 0.4127\nEpoch 7/10\n\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 183ms/step - accuracy: 0.9693 - loss: 0.0777 - val_accuracy: 0.9215 - val_loss: 0.2293\nEpoch 8/10\n\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 181ms/step - accuracy: 0.9761 - loss: 0.0728 - val_accuracy: 0.8894 - val_loss: 0.3795\nEpoch 9/10\n\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 184ms/step - accuracy: 0.9773 - loss: 0.0603 - val_accuracy: 0.9038 - val_loss: 0.3456\nEpoch 10/10\n\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 181ms/step - accuracy: 0.9753 - loss: 0.0608 - val_accuracy: 0.9103 - val_loss: 0.2973\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from keras.applications.vgg16 import preprocess_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:40:45.305629Z","iopub.execute_input":"2025-02-06T15:40:45.305954Z","iopub.status.idle":"2025-02-06T15:40:45.439197Z","shell.execute_reply.started":"2025-02-06T15:40:45.305931Z","shell.execute_reply":"2025-02-06T15:40:45.438374Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"FileUpload(value=(), accept='image/*', description='Upload')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d51e1af5a629429180a96702534f195b"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def predict(path):\n    img=image.load_img(path,target_size=(224,224))\n    x=image.img_to_array(img)\n    x=np.expand_dims(x, axis=0)\n    img_data=preprocess_input(x)\n    classes=model.predict(img_data)\n    result=int(classes[0][0])\n    if result==0:\n        print(\"Person is Affected By PNEUMONIA\")\n    else:\n        print(\"Result is Normal\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:57:48.144140Z","iopub.execute_input":"2025-02-06T15:57:48.144428Z","iopub.status.idle":"2025-02-06T15:57:48.149113Z","shell.execute_reply.started":"2025-02-06T15:57:48.144405Z","shell.execute_reply":"2025-02-06T15:57:48.148147Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"predict(\"/kaggle/input/chest-xray-pneumonia/chest_xray/val/NORMAL/NORMAL2-IM-1427-0001.jpeg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:58:14.306909Z","iopub.execute_input":"2025-02-06T15:58:14.307255Z","iopub.status.idle":"2025-02-06T15:58:14.398435Z","shell.execute_reply.started":"2025-02-06T15:58:14.307224Z","shell.execute_reply":"2025-02-06T15:58:14.397628Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\nResult is Normal\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"predict(\"/kaggle/input/chest-xray-pneumonia/chest_xray/val/PNEUMONIA/person1946_bacteria_4874.jpeg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T15:58:47.285180Z","iopub.execute_input":"2025-02-06T15:58:47.285482Z","iopub.status.idle":"2025-02-06T15:58:47.370115Z","shell.execute_reply.started":"2025-02-06T15:58:47.285448Z","shell.execute_reply":"2025-02-06T15:58:47.369230Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\nPerson is Affected By PNEUMONIA\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}